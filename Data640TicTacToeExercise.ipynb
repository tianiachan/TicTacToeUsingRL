{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data640TicTacToeExercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianiachan/TicTacToeUsingRL/blob/main/Data640TicTacToeExercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYGU9K7s1FiQ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Initialize q-table of shape (states, actions), which is (3 ** 9, 9)\n",
        "q_table = np.zeros((3 ** 9, 9))\n",
        "\n",
        "# Learning parameters\n",
        "episodes = 1000000\n",
        "learning_rate = 0.01\n",
        "num_random_episodes = 10000\n",
        "min_epsilon, max_epsilon = 0.01, 1.0\n",
        "\n",
        "# Epsilon decay function\n",
        "def get_epsilon(episode):\n",
        "  epsilon = max(min_epsilon, min(max_epsilon, num_random_episodes / (episode + 1)))\n",
        "  return epsilon\n",
        "\n",
        "# Show graph of exploration strategy\n",
        "X = np.arange(0, episodes)\n",
        "Y = np.vectorize(get_epsilon)(X)\n",
        "fig = plt.figure(figsize = (6, 6))\n",
        "plt.plot(X, Y)\n",
        "plt.xlim(0, episodes - 1)\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Epsilon\")\n",
        "plt.title(\"Exploration Strategy\")\n",
        "plt.close(fig)\n",
        "fig.savefig(\"exploration_strategy.jpg\")\n",
        "\n",
        "# Get available moves\n",
        "def get_available_moves(board):\n",
        "  available_moves = np.argwhere(board == 0).tolist()\n",
        "  return available_moves\n",
        "\n",
        "# Convert board configuration to an integer state\n",
        "def board_to_state(board):\n",
        "  n_states = 3 ** 9\n",
        "  state = 0\n",
        "\n",
        "  for x in board.flatten():\n",
        "    state += ((x + 1) / 3) * n_states\n",
        "    n_states /= 3\n",
        "\n",
        "  return int(state)\n",
        "\n",
        "# Determine if board state is terminal\n",
        "def is_terminal(board):\n",
        "  \"\"\"\n",
        "  If board is terminal, returns 1 or -1 depending on winner, or 0 if tie\n",
        "  If board is not terminal, returns None\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  \n",
        "  # Check if any columns are all the same\n",
        "  column_sum = np.sum(board, axis = 0)\n",
        "  if np.any(np.abs(column_sum) == 3):\n",
        "    return int(np.sign(column_sum[np.argmax(np.abs(column_sum))]))\n",
        "\n",
        "  # Check if any rows are all the same\n",
        "  row_sum = np.sum(board, axis = 1)\n",
        "  if np.any(np.abs(row_sum) == 3):\n",
        "    return int(np.sign(row_sum[np.argmax(np.abs(row_sum))]))\n",
        "\n",
        "  # Check if either diagonal is all the same\n",
        "  diagonal_sum = np.array([np.diag(board).sum(), np.diag(np.fliplr(board)).sum()])\n",
        "  if np.any(np.abs(diagonal_sum) == 3):\n",
        "    return int(np.sign(diagonal_sum[np.argmax(np.abs(diagonal_sum))]))\n",
        "\n",
        "  # If no win condition is satisfied, but the board if full, its a tie\n",
        "  if not np.any(board == 0):\n",
        "    return 0\n",
        "\n",
        "  # If the board is not terminal, return None\n",
        "  return None\n",
        "  \"\"\"\n",
        "\n",
        "  for turn in [-1, 1]:\n",
        "    mask = board == turn\n",
        "    out = mask.all(0).any() | mask.all(1).any()\n",
        "    out |= np.diag(mask).all() | np.diag(mask[:,::-1]).all()\n",
        "    \n",
        "    if out:\n",
        "      return turn\n",
        "\n",
        "  if not np.any(board == 0):\n",
        "    return 0\n",
        "\n",
        "  return None\n",
        "\n",
        "past_results = []\n",
        "win_probs = []\n",
        "draw_probs = []\n",
        "sum_q_table = []\n",
        "\n",
        "for episode in range(episodes):\n",
        "  epsilon = get_epsilon(episode)\n",
        "  terminal = None\n",
        "  board = np.zeros((3, 3))\n",
        "  current_state = board_to_state(board)\n",
        "  turn = 1\n",
        "  episode_memory = []\n",
        "\n",
        "  while not isinstance(terminal, int):\n",
        "    available_moves = get_available_moves(board)\n",
        "    if np.random.random() < epsilon:\n",
        "      action_square = tuple(random.choice(available_moves))\n",
        "      action = 3 * action_square[0] + action_square[1]\n",
        "    else:\n",
        "      actions = q_table[current_state] * turn\n",
        "      for action in np.argsort(actions)[::-1]:\n",
        "        action_square = [action // 3, action % 3]\n",
        "        if action_square in available_moves:\n",
        "          action_square = tuple(action_square)\n",
        "          break\n",
        "\n",
        "    board[action_square] = turn\n",
        "    new_state = board_to_state(board)\n",
        "    episode_memory.append([current_state, action, new_state])\n",
        "    turn *= -1\n",
        "    terminal = is_terminal(board)\n",
        "\n",
        "    current_state = new_state\n",
        "\n",
        "  reward = terminal\n",
        "  past_results.append(reward)\n",
        "\n",
        "  # Update q-table\n",
        "  for current_state, action, new_state in episode_memory:\n",
        "    q_table[current_state, action] = q_table[current_state, action] + learning_rate * (reward + max(q_table[new_state]) - q_table[current_state, action])\n",
        "\n",
        "  try:\n",
        "    averaging_distance = 1000\n",
        "    draw_freq, win_freq = np.unique(np.abs(past_results[-averaging_distance:]), return_counts = True)[1]\n",
        "    draw_prob = draw_freq / averaging_distance * 100\n",
        "    win_prob = win_freq / averaging_distance * 100\n",
        "\n",
        "    draw_probs.append(draw_prob)\n",
        "    win_probs.append(win_prob)\n",
        "  except:\n",
        "    # If there hasn't been at least one tie and one win, the above code block will raise an exception.\n",
        "    draw_probs.append(None)\n",
        "    win_probs.append(None)\n",
        "    \n",
        "  sum_q_table.append(np.abs(q_table).sum())\n",
        "\n",
        "  if episode % 1000 == 0:\n",
        "    try:\n",
        "      clear_output(wait = True)\n",
        "      fig = plt.figure(figsize = (15, 6))\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.plot(draw_probs, label = \"Draw Probability\")\n",
        "      plt.plot(win_probs, label = \"Win Probability\")\n",
        "      plt.xlim(0, len(draw_probs) - 1)\n",
        "      plt.ylim(0, 100)\n",
        "      plt.xlabel(\"Episode\")\n",
        "      plt.ylabel(\"Probability (%)\")\n",
        "      plt.legend()\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.plot(sum_q_table)\n",
        "      plt.xlim(0, len(sum_q_table) - 1)\n",
        "      plt.ylim(0,)\n",
        "      plt.xlabel(\"Episode\")\n",
        "      plt.ylabel(\"$\\sigma_(s, a) |Q(s, a)|$\")\n",
        "      plt.show()\n",
        "      print (\"Episode: {}, Epsilon: {:.3f}, Win Probability: {:.3f}, Draw Probability: {:.3f}\".format(episode + 1, epsilon, win_probs[-1], draw_probs[-1]))\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "np.save(\"q_table.npy\", q_table)\n",
        "np.save(\"draw_probs.npy\", draw_probs)\n",
        "np.save(\"win_probs.npy\", win_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-wDoVcvYmDJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "c810b1b5-19de-4a7a-cfd8-3eab2e0bf3a4"
      },
      "source": [
        "board = np.zeros((3, 3))\n",
        "terminal = None\n",
        "print (board, \"\\n\")\n",
        "\n",
        "while not isinstance(terminal, int):\n",
        "  current_state = board_to_state(board)\n",
        "  available_moves = get_available_moves(board)\n",
        "\n",
        "  actions = q_table[current_state] * 1\n",
        "  for action in np.argsort(actions)[::-1]:\n",
        "    action_square = [action // 3, action % 3]\n",
        "    if action_square in available_moves:\n",
        "      break\n",
        "\n",
        "  board[tuple(action_square)] = 1\n",
        "  print (board, \"\\n\")\n",
        "  terminal = is_terminal(board)\n",
        "\n",
        "  if isinstance(terminal, int):\n",
        "    break\n",
        "\n",
        "  action_square = input().split(' ')\n",
        "  action_square = (int(action_square[0]), int(action_square[1]))\n",
        "  board[action_square] = -1\n",
        "  print (board, \"\\n\")\n",
        "  terminal = is_terminal(board)\n",
        "\n",
        "  if isinstance(terminal, int):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]] \n",
            "\n",
            "[[0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]] \n",
            "\n",
            "0 0\n",
            "[[-1.  0.  0.]\n",
            " [ 0.  1.  0.]\n",
            " [ 0.  0.  0.]] \n",
            "\n",
            "[[-1.  0.  0.]\n",
            " [ 0.  1.  0.]\n",
            " [ 1.  0.  0.]] \n",
            "\n",
            "0 2\n",
            "[[-1.  0. -1.]\n",
            " [ 0.  1.  0.]\n",
            " [ 1.  0.  0.]] \n",
            "\n",
            "[[-1.  1. -1.]\n",
            " [ 0.  1.  0.]\n",
            " [ 1.  0.  0.]] \n",
            "\n",
            "2 1\n",
            "[[-1.  1. -1.]\n",
            " [ 0.  1.  0.]\n",
            " [ 1. -1.  0.]] \n",
            "\n",
            "[[-1.  1. -1.]\n",
            " [ 0.  1.  1.]\n",
            " [ 1. -1.  0.]] \n",
            "\n",
            "1 0\n",
            "[[-1.  1. -1.]\n",
            " [-1.  1.  1.]\n",
            " [ 1. -1.  0.]] \n",
            "\n",
            "[[-1.  1. -1.]\n",
            " [-1.  1.  1.]\n",
            " [ 1. -1.  1.]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}